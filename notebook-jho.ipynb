{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5f35c6",
   "metadata": {},
   "source": [
    "## Baixa conteudo da web e salva em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1d6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baixa conteudo da web e salva em disco\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "def get_file_name(url:str, response:requests.Response) -> str:\n",
    "        file_name = 'download'\n",
    "        if 'Content-Disposition' in response.headers:\n",
    "            content_disposition = response.headers.get('Content-Disposition')\n",
    "            file_name = content_disposition.split('filename=')[1].strip('\"')\n",
    "        else:\n",
    "            file_name = url.split(\"/\")[-1]\n",
    "        return file_name\n",
    "\n",
    "def generate_available_filename(directory, filename):\n",
    "\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    counter = 1\n",
    "\n",
    "    while os.path.exists(file_path):\n",
    "        new_filename = f\"{name} ({counter}){extension}\"\n",
    "        file_path = os.path.join(directory, new_filename)\n",
    "        counter += 1\n",
    "\n",
    "    return file_path\n",
    "\n",
    "def download(url:str, directory:str=os.getcwd()) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        file_name = generate_available_filename(directory, get_file_name(url, response))\n",
    "        create_directory_if_not_exists(directory)\n",
    "        with open(generate_available_filename(directory, get_file_name(url, response)), \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        return file_name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49062341",
   "metadata": {},
   "source": [
    "## File Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcdf753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip(zip_path, dataset_unzip_directory, file_to_extract) -> str:\n",
    "     remove_file(os.path.join(dataset_unzip_directory, file_to_extract))\n",
    "     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "         return zip_ref.extract(file_to_extract, dataset_unzip_directory)\n",
    " \n",
    " \n",
    "def remove_file(caminho_arquivo):\n",
    "     if os.path.exists(caminho_arquivo):\n",
    "         os.remove(caminho_arquivo)\n",
    "     else:\n",
    "         print(f\"Arquivo '{caminho_arquivo}' não encontrado.\")   \n",
    "\n",
    "def move_file(origem, destino):\n",
    "     os.replace(origem, destino)\n",
    "\n",
    "def remove_directory(directory):\n",
    "     if os.path.exists(directory):\n",
    "         os.rmdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d5364",
   "metadata": {},
   "source": [
    "## CSV Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff2821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def convert_csv_to_parquet(csv_path):\n",
    "    \"\"\"Função para converter CSV em Parquet.\"\"\"\n",
    "    try:\n",
    "        # csv_path = convert_csv_encoding(csv_path, 'latin1', 'utf-8')\n",
    "        df = pd.read_csv(csv_path, sep=';', encoding='latin1', low_memory=False)\n",
    "        parquet_path = csv_path.replace(\".csv\", \".parquet\")\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        return parquet_path\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter {csv_path} para Parquet: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_csv_encoding(csv_path, source_encoding, target_encoding='utf-8') -> str:\n",
    "    \"\"\"Função para converter a codificação de um arquivo CSV.\"\"\"\n",
    "    try:\n",
    "        df = dd.read_csv(csv_path, encoding=source_encoding)\n",
    "        remove_file(csv_path)\n",
    "        df.to_csv(csv_path, sep=';', encoding=target_encoding, index=False)\n",
    "        return csv_path\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter a codificação do arquivo {csv_path}: {e}\")\n",
    "        raise e\n",
    "\n",
    "def convert_parquet_encoding(input_parquet_path, output_parquet_path, source_encoding='latin1', target_encoding='utf-8'):\n",
    "    df = pd.read_parquet(input_parquet_path)\n",
    "    \n",
    "    for col in df.select_dtypes(include=[object]):\n",
    "        df[col] = df[col].apply(lambda x: x.encode(source_encoding).decode(target_encoding) if isinstance(x, str) else x)\n",
    "    \n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, output_parquet_path)\n",
    "    \n",
    "    print(f\"Arquivo Parquet convertido de Latin1 para UTF-8 e salvo em {output_parquet_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9530f",
   "metadata": {},
   "source": [
    "## Prepara datasets para serem ingeridos pelo notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99758ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "resources_directory = os.path.join(os.getcwd(), \"resources\")\n",
    "\n",
    "dataset_directory = os.path.join(os.getcwd(), \"dataset/2022\")\n",
    "dataset_unzip_directory= os.path.join(dataset_directory, \"unzip\")\n",
    "\n",
    "\n",
    "## DataSet Principal (Candidatos)\n",
    "resource_file = os.path.join(resources_directory, \"consulta_cand_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/consulta_cand/consulta_cand_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"consulta_cand_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    # convert_parquet_encoding(parquet_file, os.path.join(dataset_directory, \"candidatos.parquet\"))\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.parquet\"))\n",
    "\n",
    "## DataSet Complementar (Informacoes Complementares)\n",
    "resource_file = os.path.join(resources_directory, \"consulta_cand_complementar_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/consulta_cand_complementar/consulta_cand_complementar_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"consulta_cand_complementar_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.infos_adicionais.parquet\"))\n",
    "\n",
    "\n",
    "## DataSet Bens dos Candidatos\n",
    "resource_file = os.path.join(resources_directory, \"bem_candidato_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/bem_candidato/bem_candidato_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"bem_candidato_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.bens.parquet\"))\n",
    "\n",
    "\n",
    "\n",
    "## DataSet Prestação de Contas\n",
    "resource_file = os.path.join(resources_directory, \"prestacao_de_contas_eleitorais_candidatos_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/prestacao_contas/prestacao_de_contas_eleitorais_candidatos_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "\n",
    "## Despesas Contratadas\n",
    "file_to_extract = \"despesas_contratadas_candidatos_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.despesas.contratadas.parquet\"))\n",
    "\n",
    "## Despesas Contratadas Pagas\n",
    "file_to_extract = \"despesas_pagas_candidatos_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.despesas.pagas.parquet\"))\n",
    "\n",
    "## Receitas\n",
    "file_to_extract = \"receitas_candidatos_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.receitas.parquet\"))\n",
    "\n",
    "## Receitas\n",
    "file_to_extract = \"receitas_candidatos_doador_originario_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"candidatos.receitas.doador_originario.parquet\"))\n",
    "\n",
    "remove_directory(dataset_unzip_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "resources_directory = os.path.join(os.getcwd(), \"resources\")\n",
    "\n",
    "dataset_directory = os.path.join(os.getcwd(), \"dataset/2022\")\n",
    "dataset_unzip_directory= os.path.join(dataset_directory, \"unzip\")\n",
    "\n",
    "\n",
    "## DataSet Resultados\n",
    "resource_file = os.path.join(resources_directory, \"votacao_candidato_munzona_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/votacao_candidato_munzona/votacao_candidato_munzona_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"votacao_candidato_munzona_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_directory, \"resultados.votacao.canditados.parquet\"))\n",
    "\n",
    "remove_directory(dataset_unzip_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda3f94",
   "metadata": {},
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc5cd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import duckdb\n",
    "\n",
    "\n",
    "class ParquetView:\n",
    "    def __init__(self, parquet_file:str, view_name:str):\n",
    "        self.parquet_file = parquet_file\n",
    "        self.view_name = view_name\n",
    "\n",
    "    def connection_string(self):\n",
    "        return f\"CREATE VIEW '{self.view_name}' AS SELECT * FROM '{self.parquet_file}'\"\n",
    "    \n",
    "def create_view(parquet_views:List[ParquetView], con=duckdb.connect(database=':memory:')) -> duckdb.DuckDBPyConnection:\n",
    "    for view in parquet_views:\n",
    "        con.execute(view.connection_string())\n",
    "    return con\n",
    "\n",
    "def materialize_query_into_parquet(query:str, parquet_file:str, con:duckdb.DuckDBPyConnection) -> duckdb.DuckDBPyConnection:\n",
    "    con.execute(query).fetchdf().to_parquet(parquet_file, index=False)\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "844f7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRAI TABELAS CONTIDAS EM candidatos.parquet\n",
    "\n",
    "import os\n",
    "\n",
    "dataset_directory = os.path.join(os.getcwd(), \"dataset\", \"2022\")\n",
    "tables_directory = os.path.join(\"dataset\", \"2022\", \"candidatos\", \"tabelas\")\n",
    "os.makedirs(tables_directory, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect()\n",
    "candidatos_view = ParquetView(os.path.join(dataset_directory, \"candidatos.parquet\"), \"candidatos\")\n",
    "create_view([candidatos_view], con)\n",
    "\n",
    "\n",
    "## TIPOS_ELEICAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_TIPO_ELEICAO as ID,\n",
    "        NM_TIPO_ELEICAO as TIPO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"tipos_eleicao.parquet\"), con)\n",
    "\n",
    "\n",
    "#ELEICOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_ELEICAO as ID,\n",
    "        DS_ELEICAO as DESCRICAO,\n",
    "        TP_ABRANGENCIA as ABRANGENCIA,\n",
    "        NR_TURNO as TURNO,\n",
    "        CD_TIPO_ELEICAO as ID_TIPO_ELEICAO,\n",
    "        DT_ELEICAO as DATA\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"eleicoes.parquet\"), con)\n",
    "\n",
    "#CARGOS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_CARGO as ID,\n",
    "        DS_CARGO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"cargos.parquet\"), con)\n",
    "\n",
    "#SITUACOES_CANDIDATURA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATURA as ID,\n",
    "        DS_SITUACAO_CANDIDATURA as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"situacoes_candidatura.parquet\"), con)\n",
    "\n",
    "#SITUACOES_CANDIDATURA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SG_UF as SIGLA,\n",
    "        NM_UE as NOME\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"unidades_federativas.parquet\"), con)\n",
    "\n",
    "#FEDERACOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        NR_FEDERACAO as ID,\n",
    "        NM_FEDERACAO as NOME,\n",
    "        SG_FEDERACAO as SIGLA,\n",
    "        DS_COMPOSICAO_FEDERACAO as COMPOSICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "    where NR_FEDERACAO != -1\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"federacoes.parquet\"), con)\n",
    "\n",
    "\n",
    "#COLIGACOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_COLIGACAO as ID,\n",
    "        NM_COLIGACAO as NOME,\n",
    "        DS_COMPOSICAO_COLIGACAO as COMPOSICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"coligacoes.parquet\"), con)\n",
    "\n",
    "#GENEROS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_GENERO as ID,\n",
    "        DS_GENERO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"generos.parquet\"), con)\n",
    "\n",
    "#GRAUS_INSTRUCAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_GRAU_INSTRUCAO as ID,\n",
    "        DS_GRAU_INSTRUCAO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"graus_instrucao.parquet\"), con)\n",
    "\n",
    "#ESTADOS_CIVIL\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_ESTADO_CIVIL as ID,\n",
    "        DS_ESTADO_CIVIL as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"estados_civil.parquet\"), con)\n",
    "\n",
    "#CORES_RACA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_COR_RACA as ID,\n",
    "        DS_COR_RACA as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"cores_raca.parquet\"), con)\n",
    "\n",
    "#OCUPACOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_OCUPACAO as ID,\n",
    "        DS_OCUPACAO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"ocupacoes.parquet\"), con)\n",
    "\n",
    "#SITUACOES_TOTALIZACAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SIT_TOT_TURNO as ID,\n",
    "        DS_SIT_TOT_TURNO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "    where CD_SIT_TOT_TURNO != -1\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"situacoes_totalizacao.parquet\"), con)\n",
    "\n",
    "\n",
    "#CANDIDATOS\n",
    "query = \"\"\"\n",
    "   SELECT distinct        \n",
    "        SQ_CANDIDATO as ID,\n",
    "        CD_ELEICAO as ID_ELEICAO,\n",
    "        SG_UF as UF,\n",
    "        NR_PARTIDO as NUMERO_PARTIDO,\n",
    "        NR_CANDIDATO as NUMERO,\n",
    "        NM_CANDIDATO as NOME,\n",
    "        NM_URNA_CANDIDATO as NOME_URNA,\n",
    "        NR_FEDERACAO as ID_FEDERACAO,\n",
    "        SQ_COLIGACAO as ID_COLIGACAO,\n",
    "        SG_UF_NASCIMENTO as UF_NASCIMENTO,\n",
    "        DT_NASCIMENTO as DATA_NASCIMENTO,\n",
    "        NR_TITULO_ELEITORAL_CANDIDATO as NUMERO_TITULO_ELEITORAL,\n",
    "        CD_GENERO as ID_GENERO,\n",
    "        CD_GRAU_INSTRUCAO as ID_GRAU_INSTRUCAO,\n",
    "        CD_ESTADO_CIVIL as ID_ESTADO_CIVIL,\n",
    "        CD_COR_RACA as ID_COR_RACA,\n",
    "        CD_OCUPACAO as ID_OCUPACAO,\n",
    "        CD_SIT_TOT_TURNO as ID_SITUACAO_TOTALIZACAO\n",
    "\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"candidatos.parquet\"), con)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b947f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRAI TABELAS CONTIDAS EM candidatos.infos_adicionais.parquet\n",
    "\n",
    "import os\n",
    "\n",
    "dataset_directory = os.path.join(os.getcwd(), \"dataset\", \"2022\")\n",
    "tables_directory = os.path.join(\"dataset\", \"2022\", \"candidatos\", \"tabelas\")\n",
    "os.makedirs(tables_directory, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect()\n",
    "candidatos_view = ParquetView(os.path.join(dataset_directory, \"candidatos.infos_adicionais.parquet\"), \"infos_adicionais\")\n",
    "create_view([candidatos_view], con)\n",
    "\n",
    "\n",
    "## DETALHES_SITUACAO_CANDIDATURA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_DETALHE_SITUACAO_CAND as ID,\n",
    "        DS_DETALHE_SITUACAO_CAND as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"detalhes_situacao_candidatura.parquet\"), con)\n",
    "\n",
    "## NACIONALIDADES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_NACIONALIDADE as ID,\n",
    "        DS_NACIONALIDADE as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"nacionalidades.parquet\"), con)\n",
    "\n",
    "## SITUACOES_CANDIDATO_PLEITO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATO_PLEITO as ID,\n",
    "        DS_SITUACAO_CANDIDATO_PLEITO as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"situacoes_candidato_pleito.parquet\"), con)\n",
    "\n",
    "## SITUACOES_CANDIDATO_URNA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATO_URNA as ID,\n",
    "        DS_SITUACAO_CANDIDATO_URNA as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"situacoes_candidato_urna.parquet\"), con)\n",
    "\n",
    "## SITUACOES_CANDIDATO_TOTALIZACAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATO_TOT as ID,\n",
    "        DS_SITUACAO_CANDIDATO_TOT as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"situacoes_candidato_totalizacao.parquet\"), con)\n",
    "\n",
    "## INFORMACOES_ADICIONAIS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_CANDIDATO as ID_CANIDATO,\n",
    "        CD_DETALHE_SITUACAO_CAND as ID_DETALHE_SITUACAO_CANDIDATURA,\n",
    "        CD_NACIONALIDADE as ID_NACIONALIDADE,\n",
    "        NM_MUNICIPIO_NASCIMENTO as NOME_MUNICIPIO_NASCIMENTO,\n",
    "        NR_IDADE_DATA_POSSE as IDADE_POSSE,\n",
    "        VR_DESPESA_MAX_CAMPANHA as DESPESA_MAX_CAMPANHA,\n",
    "        ST_REELEICAO as REELEICAO,\n",
    "        ST_DECLARAR_BENS as DECLARAR_BENS,\n",
    "        CD_SITUACAO_CANDIDATO_PLEITO as ID_SITUACAO_CANDIDATO_PLEITO,\n",
    "        CD_SITUACAO_CANDIDATO_URNA as ID_SITUACAO_CANDIDATO_URNA,\n",
    "        ST_CANDIDATO_INSERIDO_URNA as INSERIDO_URNA,\n",
    "        NM_TIPO_DESTINACAO_VOTOS as TIPO_DESTINACAO_VOTOS,\n",
    "        CD_SITUACAO_CANDIDATO_TOT as ID_SITUACAO_CANDIDATO_TOTALIZACAO,\n",
    "        ST_PREST_CONTAS as REALIZOU_PRESTACAO_CONTAS,\n",
    "        ST_SUBSTITUIDO as SUBSTITUIDO,\n",
    "        SQ_SUBSTITUIDO as ID_CANDIDATO_SUBSTITUIDO,\n",
    "        SQ_ORDEM_SUPLENCIA as ORDEM_SUPLENCIA,\n",
    "        DT_ACEITE_CANDIDATURA as DATA_ACEITE_CANDIDATURA\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"informacoes_adicionais.parquet\"), con)\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21244e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRAI TABELAS CONTIDAS EM candidatos.bens.parquet\n",
    "\n",
    "import os\n",
    "\n",
    "dataset_directory = os.path.join(os.getcwd(), \"dataset\", \"2022\")\n",
    "tables_directory = os.path.join(\"dataset\", \"2022\", \"candidatos\", \"tabelas\")\n",
    "os.makedirs(tables_directory, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect()\n",
    "candidatos_view = ParquetView(os.path.join(dataset_directory, \"candidatos.bens.parquet\"), \"bens\")\n",
    "create_view([candidatos_view], con)\n",
    "\n",
    "\n",
    "## TIPOS_BEM_CANDIDATO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_TIPO_BEM_CANDIDATO as ID,\n",
    "        DS_TIPO_BEM_CANDIDATO as DESCRICAO\n",
    "    FROM\n",
    "        bens\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"tipos_bem.parquet\"), con)\n",
    "\n",
    "## BENS_CANDIDATO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_CANDIDATO as ID_CANDIDATO,\n",
    "        NR_ORDEM_BEM_CANDIDATO as ORDEM_BEM,\n",
    "        CD_TIPO_BEM_CANDIDATO as ID_TIPO_BEM,\n",
    "        DS_BEM_CANDIDATO as DESCRICAO,\n",
    "        VR_BEM_CANDIDATO as VALOR,\n",
    "        DT_ULT_ATUAL_BEM_CANDIDATO as DATA_ULTIMA_ATUALIZACAO,\n",
    "        HH_ULT_ATUAL_BEM_CANDIDATO as HORA_ULTIMA_ATUALIZACAO\n",
    "    FROM\n",
    "        bens\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(tables_directory, \"bens.parquet\"), con)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a344730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SQ_CANDIDATO  NR_CANDIDATO                      NM_CANDIDATO  \\\n",
      "0      100001608211          5120    BRUNNA DE SOUZA AMORIM MARCIEL   \n",
      "1      250001619350         50110        EDIANE MARIA DO NASCIMENTO   \n",
      "2       70001723597         20777    MARIA JOSÉ ALVES MORENO CABRAL   \n",
      "3       80001719700         65077    CARMEM LUCIA GOMES DE OLIVEIRA   \n",
      "4      190001619212          1388               ROBSON SOUZA SANTOS   \n",
      "...             ...           ...                               ...   \n",
      "29309  130001634154          1940              JOSE MARCIO DOS REIS   \n",
      "29310  240001614291         14000          JULIANO DA SILVA MARTINS   \n",
      "29311  240001644409         12212         ROSELÉIA LUCAS DOS SANTOS   \n",
      "29312  140001596650            22    ROSIANE CHAGAS MESQUITA EGUCHI   \n",
      "29313  170001736575         14300  GERCINALDO DO NASCIMENTO BARBOZA   \n",
      "\n",
      "      NM_URNA_CANDIDATO  CD_SITUACAO_CANDIDATURA  NR_PARTIDO SG_PARTIDO  \\\n",
      "0        BRUNNA MARCIEL                       12          51   PATRIOTA   \n",
      "1          EDIANE MARIA                       12          50       PSOL   \n",
      "2       MARIA DA ADIRPP                       12          20        PSC   \n",
      "3          CARMEM LUCIA                       12          65    PC do B   \n",
      "4          BINHO FAVELA                       12          13         PT   \n",
      "...                 ...                      ...         ...        ...   \n",
      "29309    ZE MARCIO REIS                       12          19       PODE   \n",
      "29310   JULIANO MARTINS                       12          14        PTB   \n",
      "29311                RÔ                       12          12        PDT   \n",
      "29312    ROSIANE EGUCHI                        3          22         PL   \n",
      "29313       IRMÃO TUTUI                        3          14        PTB   \n",
      "\n",
      "      SG_UF_NASCIMENTO DT_NASCIMENTO  CD_GENERO  ... CD_GRAU_INSTRUCAO  \\\n",
      "0                   PI    11/06/1982          4  ...                 6   \n",
      "1                   PE    10/10/1983          4  ...                 2   \n",
      "2                   MG    07/04/1964          4  ...                 6   \n",
      "3                   AL    09/04/1977          4  ...                 8   \n",
      "4                   RJ    07/08/1981          2  ...                 6   \n",
      "...                ...           ...        ...  ...               ...   \n",
      "29309               MG    31/12/1983          2  ...                 6   \n",
      "29310               SC    13/02/1981          2  ...                 8   \n",
      "29311               SC    03/05/1980          4  ...                 7   \n",
      "29312   Não divulgável          None         -4  ...                -4   \n",
      "29313   Não divulgável          None         -4  ...                -4   \n",
      "\n",
      "           DS_GRAU_INSTRUCAO CD_ESTADO_CIVIL  DS_ESTADO_CIVIL CD_COR_RACA  \\\n",
      "0      ENSINO MÉDIO COMPLETO               3        CASADO(A)           1   \n",
      "1               LÊ E ESCREVE               1      SOLTEIRO(A)           2   \n",
      "2      ENSINO MÉDIO COMPLETO               3        CASADO(A)           3   \n",
      "3          SUPERIOR COMPLETO               1      SOLTEIRO(A)           2   \n",
      "4      ENSINO MÉDIO COMPLETO               1      SOLTEIRO(A)           3   \n",
      "...                      ...             ...              ...         ...   \n",
      "29309  ENSINO MÉDIO COMPLETO               1      SOLTEIRO(A)           1   \n",
      "29310      SUPERIOR COMPLETO               3        CASADO(A)           1   \n",
      "29311    SUPERIOR INCOMPLETO               1      SOLTEIRO(A)           1   \n",
      "29312         NÃO DIVULGÁVEL              -4   NÃO DIVULGÁVEL          -4   \n",
      "29313         NÃO DIVULGÁVEL              -4   NÃO DIVULGÁVEL          -4   \n",
      "\n",
      "          DS_COR_RACA CD_OCUPACAO  \\\n",
      "0              BRANCA         595   \n",
      "1               PRETA         598   \n",
      "2               PARDA         598   \n",
      "3               PRETA         598   \n",
      "4               PARDA         599   \n",
      "...               ...         ...   \n",
      "29309          BRANCA         593   \n",
      "29310          BRANCA         593   \n",
      "29311          BRANCA         593   \n",
      "29312  NÃO DIVULGÁVEL          -4   \n",
      "29313  NÃO DIVULGÁVEL          -4   \n",
      "\n",
      "                                        DS_OCUPACAO CD_SIT_TOT_TURNO  \\\n",
      "0      AGENTE DE SERVIÇOS FUNERÁRIOS E EMBALSAMADOR                5   \n",
      "1                               EMPREGADO DOMÉSTICO                2   \n",
      "2                               EMPREGADO DOMÉSTICO                4   \n",
      "3                               EMPREGADO DOMÉSTICO                5   \n",
      "4                                   GUIA DE TURISMO                5   \n",
      "...                                             ...              ...   \n",
      "29309                                   DESPACHANTE                5   \n",
      "29310                                   DESPACHANTE                5   \n",
      "29311                                   DESPACHANTE                5   \n",
      "29312                                NÃO DIVULGÁVEL               -1   \n",
      "29313                                NÃO DIVULGÁVEL               -1   \n",
      "\n",
      "       DS_SIT_TOT_TURNO  \n",
      "0              SUPLENTE  \n",
      "1         ELEITO POR QP  \n",
      "2            NÃO ELEITO  \n",
      "3              SUPLENTE  \n",
      "4              SUPLENTE  \n",
      "...                 ...  \n",
      "29309          SUPLENTE  \n",
      "29310          SUPLENTE  \n",
      "29311          SUPLENTE  \n",
      "29312            #NULO#  \n",
      "29313            #NULO#  \n",
      "\n",
      "[29314 rows x 21 columns]\n",
      "View materializada e salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "# Criar uma conexão DuckDB em memória\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Carregar os dois arquivos Parquet\n",
    "def create_views(con, candidatos_path, candidatos_bens_path):\n",
    "    con.execute(f\"CREATE VIEW candidatos AS SELECT * FROM '{candidatos_path}'\")\n",
    "    con.execute(f\"CREATE VIEW candidatos_bens AS SELECT * FROM '{candidatos_bens_path}'\")\n",
    "\n",
    "candidatos_path = 'dataset/2022/candidatos.parquet'\n",
    "candidatos_bens_path = 'dataset/2022/candidatos.bens.parquet'\n",
    "\n",
    "create_views(con, candidatos_path, candidatos_bens_path)\n",
    "con.execute(\"CREATE VIEW candidatos_bens AS SELECT * FROM 'dataset/2022/candidatos.bens.parquet'\")\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        candidato.SQ_CANDIDATO,\n",
    "        candidato.NM_CANDIDATO,\n",
    "        candidato.NM_URNA_CANDIDATO,\n",
    "        candidato.NR_CANDIDATO,\n",
    "        candidato.CD_SITUACAO_CANDIDATURA,\n",
    "        bem.*\n",
    "    FROM candidatos cantidato\n",
    "    inner join candidatos_bens bem on bem.SQ_CANDIDATO = cantidato.SQ_CANDIDATO\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Executar a consulta para combinar as tabelas (JOIN, UNION, etc.)\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        candidatos.SQ_CANDIDATO,\n",
    "        candidatos.NR_CANDIDATO,\n",
    "        candidatos.NM_CANDIDATO,\n",
    "        candidatos.NM_URNA_CANDIDATO,\n",
    "        candidatos.CD_SITUACAO_CANDIDATURA,\n",
    "        candidatos.NR_PARTIDO,\n",
    "        candidatos.SG_PARTIDO,\n",
    "        candidatos.SG_UF_NASCIMENTO,\n",
    "        candidatos.DT_NASCIMENTO,\n",
    "        candidatos.CD_GENERO,\n",
    "        candidatos.DS_GENERO,\n",
    "        candidatos.CD_GRAU_INSTRUCAO,\n",
    "        candidatos.DS_GRAU_INSTRUCAO,\n",
    "        candidatos.CD_ESTADO_CIVIL,\n",
    "        candidatos.DS_ESTADO_CIVIL,\n",
    "        candidatos.CD_COR_RACA,\n",
    "        candidatos.DS_COR_RACA,\n",
    "        candidatos.CD_OCUPACAO,\n",
    "        candidatos.DS_OCUPACAO,\n",
    "        candidatos.CD_SIT_TOT_TURNO,\n",
    "        candidatos.DS_SIT_TOT_TURNO,\n",
    "    FROM candidatos\n",
    "\"\"\"\n",
    "# Obter o resultado como um DataFrame\n",
    "df_resultante = con.execute(query).fetchdf()\n",
    "\n",
    "print(df_resultante)\n",
    "\n",
    "views_directory = os.path.join(os.getcwd(), \"dataset\", \"views\")\n",
    "os.makedirs(views_directory, exist_ok=True)\n",
    "\n",
    "# Salvar o resultado em um novo arquivo Parquet\n",
    "df_resultante.to_parquet(os.path.join(views_directory, \"candidatos.dados.base.parquet\"), index=False)\n",
    "\n",
    "print(\"View materializada e salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a41ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Caminhos dos arquivos Parquet\n",
    "arquivos_parquet = [\n",
    "    'dataset/2022/candidatos.bens.parquet',\n",
    "    'dataset/2022/candidatos.despesas.contratadas.parquet',\n",
    "    'dataset/2022/candidatos.despesas.pagas.parquet',\n",
    "    'dataset/2022/candidatos.infos_adicionais.parquet',\n",
    "    'dataset/2022/candidatos.parquet',\n",
    "    'dataset/2022/candidatos.receitas.doador_originario.parquet',\n",
    "    'dataset/2022/candidatos.receitas.parquet',\n",
    "    'dataset/2022/resultados.votacao.canditados.parquet'\n",
    "]\n",
    "\n",
    "# Conectar ao DuckDB e salvar o banco em um arquivo .db\n",
    "con = duckdb.connect('meu_banco.db')\n",
    "\n",
    "# Iterar sobre os arquivos Parquet e inserir os dados em uma tabela no banco .db\n",
    "for arquivo in arquivos_parquet:\n",
    "    # Ler o arquivo Parquet e inserir no banco DuckDB\n",
    "    con.execute(f\"COPY (SELECT * FROM '{arquivo}') TO 'meu_banco.db' (FORMAT PARQUET)\")\n",
    "    print(f\"Arquivo {arquivo} inserido com sucesso no banco!\")\n",
    "\n",
    "# Verificar o conteúdo da tabela (opcional)\n",
    "resultado = con.execute(\"SELECT * FROM 'meu_banco.db' LIMIT 10\").fetchdf()\n",
    "print(resultado)\n",
    "\n",
    "# Fechar a conexão\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c98ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Ler o esquema do arquivo Parquet\n",
    "arquivo_parquet = 'dataset/2022/candidatos.parquet'\n",
    "parquet_file = pq.ParquetFile(arquivo_parquet)\n",
    "\n",
    "# Exibir o esquema do arquivo Parquet\n",
    "print(parquet_file.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ecb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Diretório onde os arquivos .parquet estão localizados\n",
    "diretorio_parquet = 'dataset/2022'\n",
    "# Conecta ao banco de dados SQLite (ou cria um novo)\n",
    "conn = sqlite3.connect('seu_banco_de_dados.sqlite')\n",
    "\n",
    "# Itera sobre os arquivos .parquet no diretório\n",
    "for arquivo in os.listdir(diretorio_parquet):\n",
    "    if arquivo.endswith('.parquet'):\n",
    "        # Lê o arquivo .parquet\n",
    "        caminho_completo = os.path.join(diretorio_parquet, arquivo)\n",
    "        df = pd.read_parquet(caminho_completo)\n",
    "        \n",
    "        # Define o nome da tabela com base no nome do arquivo\n",
    "        nome_tabela = os.path.splitext(arquivo)[0]  # Remove a extensão .parquet\n",
    "\n",
    "        # Insere os dados no banco de dados\n",
    "        df.to_sql(nome_tabela, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Fecha a conexão\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpad-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
