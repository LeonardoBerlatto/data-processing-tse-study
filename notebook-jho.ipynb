{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5f35c6",
   "metadata": {},
   "source": [
    "## Baixa conteudo da web e salva em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1d6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baixa conteudo da web e salva em disco\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "def get_file_name(url:str, response:requests.Response) -> str:\n",
    "        file_name = 'download'\n",
    "        if 'Content-Disposition' in response.headers:\n",
    "            content_disposition = response.headers.get('Content-Disposition')\n",
    "            file_name = content_disposition.split('filename=')[1].strip('\"')\n",
    "        else:\n",
    "            file_name = url.split(\"/\")[-1]\n",
    "        return file_name\n",
    "\n",
    "def generate_available_filename(directory, filename):\n",
    "\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    counter = 1\n",
    "\n",
    "    while os.path.exists(file_path):\n",
    "        new_filename = f\"{name} ({counter}){extension}\"\n",
    "        file_path = os.path.join(directory, new_filename)\n",
    "        counter += 1\n",
    "\n",
    "    return file_path\n",
    "\n",
    "def download(url:str, directory:str=os.getcwd()) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        file_name = generate_available_filename(directory, get_file_name(url, response))\n",
    "        create_directory_if_not_exists(directory)\n",
    "        with open(generate_available_filename(directory, get_file_name(url, response)), \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        return file_name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49062341",
   "metadata": {},
   "source": [
    "## File Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdf753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip(zip_path, dataset_unzip_directory, file_to_extract) -> str:\n",
    "     remove_file(os.path.join(dataset_unzip_directory, file_to_extract))\n",
    "     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "         return zip_ref.extract(file_to_extract, dataset_unzip_directory)\n",
    " \n",
    " \n",
    "def remove_file(caminho_arquivo):\n",
    "     if os.path.exists(caminho_arquivo):\n",
    "         os.remove(caminho_arquivo)\n",
    "     else:\n",
    "         print(f\"Arquivo '{caminho_arquivo}' não encontrado.\")   \n",
    "\n",
    "def move_file(origem, destino):\n",
    "     os.replace(origem, destino)\n",
    "\n",
    "def remove_directory(directory):\n",
    "     if os.path.exists(directory):\n",
    "         os.rmdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d5364",
   "metadata": {},
   "source": [
    "## CSV Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def convert_csv_to_parquet(csv_path):\n",
    "    \"\"\"Função para converter CSV em Parquet.\"\"\"\n",
    "    try:\n",
    "        # csv_path = convert_csv_encoding(csv_path, 'latin1', 'utf-8')\n",
    "        df = pd.read_csv(csv_path, sep=';', encoding='latin1', low_memory=False)\n",
    "        parquet_path = csv_path.replace(\".csv\", \".parquet\")\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        return parquet_path\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter {csv_path} para Parquet: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_csv_encoding(csv_path, source_encoding, target_encoding='utf-8') -> str:\n",
    "    \"\"\"Função para converter a codificação de um arquivo CSV.\"\"\"\n",
    "    try:\n",
    "        df = dd.read_csv(csv_path, encoding=source_encoding)\n",
    "        remove_file(csv_path)\n",
    "        df.to_csv(csv_path, sep=';', encoding=target_encoding, index=False)\n",
    "        return csv_path\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter a codificação do arquivo {csv_path}: {e}\")\n",
    "        raise e\n",
    "\n",
    "def convert_parquet_encoding(input_parquet_path, output_parquet_path, source_encoding='latin1', target_encoding='utf-8'):\n",
    "    df = pd.read_parquet(input_parquet_path)\n",
    "    \n",
    "    for col in df.select_dtypes(include=[object]):\n",
    "        df[col] = df[col].apply(lambda x: x.encode(source_encoding).decode(target_encoding) if isinstance(x, str) else x)\n",
    "    \n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, output_parquet_path)\n",
    "    \n",
    "    print(f\"Arquivo Parquet convertido de Latin1 para UTF-8 e salvo em {output_parquet_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9530f",
   "metadata": {},
   "source": [
    "## Prepara datasets para serem ingeridos pelo notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99758ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "resources_directory = os.path.join(os.getcwd(), \"dataset\", \"2022\", \"resources\")\n",
    "\n",
    "dataset_raw_directory = os.path.join(os.getcwd(), \"dataset\", \"2022\", \"raw\")\n",
    "dataset_unzip_directory= os.path.join(dataset_raw_directory, \"unzip\")\n",
    "\n",
    "\n",
    "## DataSet Principal (Candidatos)\n",
    "resource_file = os.path.join(resources_directory, \"consulta_cand_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/consulta_cand/consulta_cand_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"consulta_cand_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    # convert_parquet_encoding(parquet_file, os.path.join(dataset_directory, \"candidatos.parquet\"))\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.parquet\"))\n",
    "\n",
    "## DataSet Complementar (Informacoes Complementares)\n",
    "resource_file = os.path.join(resources_directory, \"consulta_cand_complementar_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/consulta_cand_complementar/consulta_cand_complementar_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"consulta_cand_complementar_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.infos_adicionais.parquet\"))\n",
    "\n",
    "\n",
    "## DataSet Bens dos Candidatos\n",
    "resource_file = os.path.join(resources_directory, \"bem_candidato_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/bem_candidato/bem_candidato_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"bem_candidato_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.bens.parquet\"))\n",
    "\n",
    "\n",
    "\n",
    "## DataSet Prestação de Contas\n",
    "resource_file = os.path.join(resources_directory, \"prestacao_de_contas_eleitorais_candidatos_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/prestacao_contas/prestacao_de_contas_eleitorais_candidatos_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "\n",
    "## Despesas Contratadas\n",
    "file_to_extract = \"despesas_contratadas_candidatos_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.despesas.contratadas.parquet\"))\n",
    "\n",
    "## Despesas Contratadas Pagas\n",
    "file_to_extract = \"despesas_pagas_candidatos_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.despesas.pagas.parquet\"))\n",
    "\n",
    "## Receitas\n",
    "file_to_extract = \"receitas_candidatos_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.receitas.parquet\"))\n",
    "\n",
    "## Receitas\n",
    "file_to_extract = \"receitas_candidatos_doador_originario_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"candidatos.receitas.doador_originario.parquet\"))\n",
    "\n",
    "## DataSet Resultados\n",
    "resource_file = os.path.join(resources_directory, \"votacao_candidato_munzona_2022.zip\")\n",
    "if not os.path.exists(resource_file):\n",
    "    URL = 'https://cdn.tse.jus.br/estatistica/sead/odsele/votacao_candidato_munzona/votacao_candidato_munzona_2022.zip'\n",
    "    resource_file = download(URL, resources_directory)\n",
    "\n",
    "file_to_extract = \"votacao_candidato_munzona_2022_BRASIL.csv\"\n",
    "file_extracted = unzip(resource_file, dataset_unzip_directory, file_to_extract)\n",
    "parquet_file = convert_csv_to_parquet(file_extracted)\n",
    "if parquet_file:\n",
    "    remove_file(file_extracted)\n",
    "    move_file(parquet_file, os.path.join(dataset_raw_directory, \"resultados.votacao.canditados.parquet\"))\n",
    "\n",
    "remove_directory(dataset_unzip_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda3f94",
   "metadata": {},
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc5cd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import duckdb\n",
    "\n",
    "\n",
    "class ParquetView:\n",
    "    def __init__(self, parquet_file:str, view_name:str):\n",
    "        self.parquet_file = parquet_file\n",
    "        self.view_name = view_name\n",
    "\n",
    "    def connection_string(self):\n",
    "        return f\"CREATE VIEW '{self.view_name}' AS SELECT * FROM '{self.parquet_file}'\"\n",
    "    \n",
    "def create_view(parquet_views:List[ParquetView], con=duckdb.connect(database=':memory:')) -> duckdb.DuckDBPyConnection:\n",
    "    for view in parquet_views:\n",
    "        con.execute(view.connection_string())\n",
    "    return con\n",
    "\n",
    "def materialize_query_into_parquet(query:str, parquet_file:str, con:duckdb.DuckDBPyConnection) -> duckdb.DuckDBPyConnection:\n",
    "    con.execute(query).fetchdf().to_parquet(parquet_file, index=False)\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5749405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_raw_directory = os.path.join(os.getcwd(), \"dataset\", \"2022\", \"raw\")\n",
    "dataset_processed_directory = os.path.join(\"dataset\", \"2022\", \"processed\")\n",
    "os.makedirs(dataset_processed_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf72729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Criando as views dos arquivos parquet\n",
    "\n",
    "bens_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.bens.parquet\"), \"bens\")\n",
    "despesas_contratadas_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.despesas.contratadas.parquet\"), \"despesas_contratadas\")\n",
    "despesas_pagas_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.despesas.pagas.parquet\"), \"despesas_pagas\")\n",
    "infos_adicionais_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.infos_adicionais.parquet\"), \"infos_adicionais\")\n",
    "candidatos_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.parquet\"), \"candidatos\")\n",
    "receitas_doador_originario_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.receitas.doador_originario.parquet\"), \"receitas_doador_originario\")\n",
    "receitas_view = ParquetView(os.path.join(dataset_raw_directory, \"candidatos.receitas.parquet\"), \"receitas\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "## TIPOS_ELEICAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_TIPO_ELEICAO as ID,\n",
    "        NM_TIPO_ELEICAO as TIPO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"tipos_eleicao.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#ELEICOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_ELEICAO as ID,\n",
    "        DS_ELEICAO as DESCRICAO,\n",
    "        TP_ABRANGENCIA as ABRANGENCIA,\n",
    "        NR_TURNO as TURNO,\n",
    "        CD_TIPO_ELEICAO as ID_TIPO_ELEICAO,\n",
    "        DT_ELEICAO as DATA\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"eleicoes.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#SITUACOES_CANDIDATURA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATURA as ID,\n",
    "        DS_SITUACAO_CANDIDATURA as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"situacoes_candidatura.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#UNIDADES_FEDERATIVAS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SG_UF as SIGLA,\n",
    "        NM_UE as NOME\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"unidades_federativas.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#FEDERACOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        NR_FEDERACAO as ID,\n",
    "        NM_FEDERACAO as NOME,\n",
    "        SG_FEDERACAO as SIGLA,\n",
    "        DS_COMPOSICAO_FEDERACAO as COMPOSICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"federacoes.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#COLIGACOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_COLIGACAO as ID,\n",
    "        NM_COLIGACAO as NOME,\n",
    "        DS_COMPOSICAO_COLIGACAO as COMPOSICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"coligacoes.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#GENEROS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_GENERO as ID,\n",
    "        DS_GENERO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"generos.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#GRAUS_INSTRUCAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_GRAU_INSTRUCAO as ID,\n",
    "        DS_GRAU_INSTRUCAO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"graus_instrucao.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#ESTADOS_CIVIL\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_ESTADO_CIVIL as ID,\n",
    "        DS_ESTADO_CIVIL as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"estados_civil.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#CORES_RACA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_COR_RACA as ID,\n",
    "        DS_COR_RACA as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"cores_raca.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#OCUPACOES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_OCUPACAO as ID,\n",
    "        DS_OCUPACAO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"ocupacoes.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#SITUACOES_TOTALIZACAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SIT_TOT_TURNO as ID,\n",
    "        DS_SIT_TOT_TURNO as DESCRICAO\n",
    "    FROM\n",
    "        candidatos\n",
    "    where CD_SIT_TOT_TURNO != -1\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"situacoes_totalizacao.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([candidatos_view], con)\n",
    "#CANDIDATOS\n",
    "query = \"\"\"\n",
    "   SELECT distinct        \n",
    "        SQ_CANDIDATO as ID,\n",
    "        CD_ELEICAO as ID_ELEICAO,\n",
    "        SG_UF as UF,\n",
    "        NR_PARTIDO as NUMERO_PARTIDO,\n",
    "        NR_CANDIDATO as NUMERO,\n",
    "        NM_CANDIDATO as NOME,\n",
    "        NM_URNA_CANDIDATO as NOME_URNA,\n",
    "        NR_FEDERACAO as ID_FEDERACAO,\n",
    "        SQ_COLIGACAO as ID_COLIGACAO,\n",
    "        SG_UF_NASCIMENTO as UF_NASCIMENTO,\n",
    "        DT_NASCIMENTO as DATA_NASCIMENTO,\n",
    "        NR_TITULO_ELEITORAL_CANDIDATO as NUMERO_TITULO_ELEITORAL,\n",
    "        CD_GENERO as ID_GENERO,\n",
    "        CD_GRAU_INSTRUCAO as ID_GRAU_INSTRUCAO,\n",
    "        CD_ESTADO_CIVIL as ID_ESTADO_CIVIL,\n",
    "        CD_COR_RACA as ID_COR_RACA,\n",
    "        CD_OCUPACAO as ID_OCUPACAO,\n",
    "        CD_SIT_TOT_TURNO as ID_SITUACAO_TOTALIZACAO\n",
    "\n",
    "    FROM\n",
    "        candidatos\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"candidatos.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([infos_adicionais_view], con)\n",
    "## DETALHES_SITUACAO_CANDIDATURA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_DETALHE_SITUACAO_CAND as ID,\n",
    "        DS_DETALHE_SITUACAO_CAND as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"detalhes_situacao_candidatura.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([infos_adicionais_view], con)\n",
    "## NACIONALIDADES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_NACIONALIDADE as ID,\n",
    "        DS_NACIONALIDADE as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"nacionalidades.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([infos_adicionais_view], con)\n",
    "## SITUACOES_CANDIDATO_PLEITO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATO_PLEITO as ID,\n",
    "        DS_SITUACAO_CANDIDATO_PLEITO as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"situacoes_candidato_pleito.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([infos_adicionais_view], con)\n",
    "## SITUACOES_CANDIDATO_URNA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATO_URNA as ID,\n",
    "        DS_SITUACAO_CANDIDATO_URNA as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"situacoes_candidato_urna.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([infos_adicionais_view], con)\n",
    "## SITUACOES_CANDIDATO_TOTALIZACAO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_SITUACAO_CANDIDATO_TOT as ID,\n",
    "        DS_SITUACAO_CANDIDATO_TOT as DESCRICAO\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"situacoes_candidato_totalizacao.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([infos_adicionais_view], con)\n",
    "## INFORMACOES_ADICIONAIS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_CANDIDATO as ID_CANIDATO,\n",
    "        CD_DETALHE_SITUACAO_CAND as ID_DETALHE_SITUACAO_CANDIDATURA,\n",
    "        CD_NACIONALIDADE as ID_NACIONALIDADE,\n",
    "        NM_MUNICIPIO_NASCIMENTO as NOME_MUNICIPIO_NASCIMENTO,\n",
    "        NR_IDADE_DATA_POSSE as IDADE_POSSE,\n",
    "        VR_DESPESA_MAX_CAMPANHA as DESPESA_MAX_CAMPANHA,\n",
    "        ST_REELEICAO as REELEICAO,\n",
    "        ST_DECLARAR_BENS as DECLARAR_BENS,\n",
    "        CD_SITUACAO_CANDIDATO_PLEITO as ID_SITUACAO_CANDIDATO_PLEITO,\n",
    "        CD_SITUACAO_CANDIDATO_URNA as ID_SITUACAO_CANDIDATO_URNA,\n",
    "        ST_CANDIDATO_INSERIDO_URNA as INSERIDO_URNA,\n",
    "        NM_TIPO_DESTINACAO_VOTOS as TIPO_DESTINACAO_VOTOS,\n",
    "        CD_SITUACAO_CANDIDATO_TOT as ID_SITUACAO_CANDIDATO_TOTALIZACAO,\n",
    "        ST_PREST_CONTAS as REALIZOU_PRESTACAO_CONTAS,\n",
    "        ST_SUBSTITUIDO as SUBSTITUIDO,\n",
    "        SQ_SUBSTITUIDO as ID_CANDIDATO_SUBSTITUIDO,\n",
    "        SQ_ORDEM_SUPLENCIA as ORDEM_SUPLENCIA,\n",
    "        DT_ACEITE_CANDIDATURA as DATA_ACEITE_CANDIDATURA\n",
    "    FROM\n",
    "        infos_adicionais\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"informacoes_adicionais.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([bens_view], con)\n",
    "## TIPOS_BEM_CANDIDATO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_TIPO_BEM_CANDIDATO as ID,\n",
    "        DS_TIPO_BEM_CANDIDATO as DESCRICAO\n",
    "    FROM\n",
    "        bens\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"tipos_bem.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([bens_view], con)\n",
    "## BENS_CANDIDATO\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_CANDIDATO as ID_CANDIDATO,\n",
    "        NR_ORDEM_BEM_CANDIDATO as ORDEM_BEM,\n",
    "        CD_TIPO_BEM_CANDIDATO as ID_TIPO_BEM,\n",
    "        DS_BEM_CANDIDATO as DESCRICAO,\n",
    "        VR_BEM_CANDIDATO as VALOR,\n",
    "        DT_ULT_ATUAL_BEM_CANDIDATO as DATA_ULTIMA_ATUALIZACAO,\n",
    "        HH_ULT_ATUAL_BEM_CANDIDATO as HORA_ULTIMA_ATUALIZACAO\n",
    "    FROM\n",
    "        bens\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"bens.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_contratadas_view], con)\n",
    "## TIPOS_FORNECEDOR\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_TIPO_FORNECEDOR as ID,\n",
    "        DS_TIPO_FORNECEDOR as DESCRICAO\n",
    "    FROM\n",
    "        despesas_contratadas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"tipos_fornecedor.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_contratadas_view], con)\n",
    "## CNAES\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_CNAE_FORNECEDOR as ID,\n",
    "        DS_CNAE_FORNECEDOR as DESCRICAO\n",
    "    FROM\n",
    "        despesas_contratadas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"cnaes.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_contratadas_view], con)\n",
    "## MUNICIPIOS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_MUNICIPIO_FORNECEDOR as ID,\n",
    "        NM_MUNICIPIO_FORNECEDOR as NOME\n",
    "    FROM\n",
    "        despesas_contratadas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"municipios.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_contratadas_view], con)\n",
    "## ORIGENS_DESPESA\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_ORIGEM_DESPESA as ID,\n",
    "        DS_ORIGEM_DESPESA as DESCRICAO\n",
    "    FROM\n",
    "        despesas_contratadas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"origens_despesa.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_contratadas_view], con)\n",
    "## DESPESAS_CONTRATADAS\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_DESPESA as ID,\n",
    "        CD_ELEICAO as ID_ELEICAO,\n",
    "        SQ_PRESTADOR_CONTAS as ID_CANIDATO_PRESTADOR,\n",
    "        SQ_CANDIDATO as ID_CANDIDATO,\n",
    "        SG_UF as UF,\n",
    "        TP_PRESTACAO_CONTAS as TIPO_PRESTACAO_CONTAS,\n",
    "        DT_PRESTACAO_CONTAS as DATA_PRESTACAO_CONTAS,\n",
    "        CD_TIPO_FORNECEDOR as ID_TIPO_FORNECEDOR,\n",
    "        CD_CNAE_FORNECEDOR as ID_CNAE_FORNECEDOR,\n",
    "        SG_UF_FORNECEDOR as UF_FORNECEDOR,\n",
    "        CD_MUNICIPIO_FORNECEDOR as ID_MUNICIPIO_FORNECEDOR,\n",
    "        SQ_CANDIDATO_FORNECEDOR as ID_CANDIDATO_FORNECEDOR,\n",
    "        DS_TIPO_DOCUMENTO as TIPO_DOCUMENTO,\n",
    "        CD_ORIGEM_DESPESA as ID_ORIGEM_DESPESA,\n",
    "        VR_DESPESA_CONTRATADA as VALOR\n",
    "    FROM\n",
    "        despesas_contratadas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"despesas_contratadas.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_pagas_view], con)\n",
    "## TIPOS_FORNECEDOR\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_NATUREZA_DESPESA as ID,\n",
    "        DS_NATUREZA_DESPESA as DESCRICAO\n",
    "    FROM\n",
    "        despesas_pagas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"naturezas_depesa.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_pagas_view], con)\n",
    "## TIPOS_FORNECEDOR\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        CD_ESPECIE_RECURSO as ID,\n",
    "        DS_ESPECIE_RECURSO as DESCRICAO\n",
    "    FROM\n",
    "        despesas_pagas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"especies.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_pagas_view], con)\n",
    "## TIPOS_FORNECEDOR\n",
    "query = \"\"\"\n",
    "   SELECT distinct\n",
    "        SQ_DESPESA as ID_DESPESA,\n",
    "        CD_ELEICAO as ID_ELEICAO,\n",
    "        DS_DESPESA as DESCRICAO,\n",
    "        CD_ESPECIE_RECURSO as ID_ESPECIE_RECURSO,\n",
    "        DT_PAGTO_DESPESA as DATA_PAGAMENTO,\n",
    "        VR_PAGTO_DESPESA as VALOR_PAGO,\n",
    "\n",
    "    FROM\n",
    "        despesas_pagas\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"despesas_pagas.parquet\"), con)\n",
    "con.close()\n",
    "\n",
    "\n",
    "con = duckdb.connect()\n",
    "create_view([despesas_contratadas_view, candidatos_view], con)\n",
    "#CARGOS\n",
    "query = \"\"\"\n",
    "    SELECT distinct \n",
    "        ID,\n",
    "        upper(DESCRICAO) AS DESCRICAO\n",
    "    FROM (\n",
    "        SELECT distinct\n",
    "            CD_CARGO as ID,\n",
    "            DS_CARGO as DESCRICAO\n",
    "        FROM\n",
    "            despesas_contratadas\n",
    "        UNION\n",
    "        SELECT distinct\n",
    "            CD_CARGO as ID,\n",
    "            DS_CARGO as DESCRICAO\n",
    "        FROM\n",
    "            candidatos\n",
    "        ) as CARGOS\n",
    "\"\"\"\n",
    "materialize_query_into_parquet(query, os.path.join(dataset_processed_directory, \"cargos.parquet\"), con)\n",
    "con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpad-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
